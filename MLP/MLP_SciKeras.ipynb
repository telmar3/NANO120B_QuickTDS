{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro from SciKeras\n",
    "\n",
    "Example to set up a TensorFlow neural network using SciKeras.\n",
    "\n",
    "from: https://adriangb.com/scikeras/refs/heads/master/notebooks/Basic_Usage.html#3.-Training-a-regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "print(\"num of cpus:\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random dataset\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_regr, y_regr = make_regression(1000, 20, n_informative=10, random_state=0)\n",
    "\n",
    "X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functionalize the creation of the neural network\n",
    "\n",
    "def get_reg(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "#Assigns Regressor model that calls the get_reg function\n",
    "\n",
    "reg = KerasRegressor(\n",
    "    model=get_reg,\n",
    "    loss=\"mse\",\n",
    "    metrics=[KerasRegressor.r_squared],\n",
    "    #hidden_layer_sizes=(100,),\n",
    "    #dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_regr, y_regr);\n",
    "y_pred = reg.predict(X_regr[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w/ GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "print(\"num of cpus:\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the .csv file into a pandas DataFrame\n",
    "data = pd.read_csv('../data/topFeatures_v2.csv', index_col=0)\n",
    "targets = pd.read_csv('../data/def_param/def_param_v2.csv', index_col=0)\n",
    "ground_truth = pd.read_csv('../data/ground_truth_featurized/ground_truth_topFeatures_v2.csv', index_col=0)\n",
    "targets=np.log10(targets)\n",
    "display(data)\n",
    "display(ground_truth)\n",
    "display(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "#add pipeline\n",
    "#Split into train and test sets\n",
    "X_train, X_test = train_test_split(data, test_size = 0.2, random_state = 42)\n",
    "y_train, y_test = train_test_split(targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Define the data preprocessing steps and the model\n",
    "preprocessor = make_pipeline(StandardScaler())\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "pipeline = make_pipeline(preprocessor, model)\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Cross-validation score: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {cv_scores.mean()}\")\n",
    "\n",
    "# Fit the model on the entire training set and evaluate on the test set\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Test set score : {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_norm = scaler.fit_transform(X_train.values)\n",
    "X_test_norm = scaler.fit_transform(X_test.values)\n",
    "#gt_norm = scaler.fit_transform(ground_truth.values)\n",
    "\n",
    "X_train_transform = pd.DataFrame(X_train_norm, index=X_train.index, columns=X_train.columns)\n",
    "X_test_transform = pd.DataFrame(X_test_norm, index=X_test.index, columns=X_test.columns)\n",
    "#gt_transform = pd.DataFrame(gt_norm, index=ground_truth.index, columns=ground_truth.columns)\n",
    "\n",
    "#display(X_train_transform)\n",
    "#display(X_test_transform)\n",
    "X_train_transform.describe()\n",
    "X_test_transform.describe()\n",
    "#gt_transform.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measures alpha, to be used ass activity_regularizer=l2(alpha)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = [c for c in X_train_transform.columns]\n",
    "cv_results = []\n",
    "coeffs = []\n",
    "alphas = np.logspace(1, 2, 100)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for alpha in alphas: #set up an array for alpha\n",
    "    ridge = linear_model.Ridge(alpha=alpha, max_iter=10000) #iterate through alpha values\n",
    "    ridge.fit(X_train_transform, y_train)#fit the norm_train_X and our target data column (form_y)\n",
    "    scores = cross_validate(ridge, X_train_transform, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "    cv_results.append([alpha, -np.mean(scores[\"test_score\"])] + list(ridge.coef_))\n",
    "\n",
    "cv_results = pd.DataFrame(cv_results, columns=[\"alpha\", \"score\"] + features[0:8])\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.plot(cv_results[\"alpha\"], cv_results[\"score\"], \"-x\")\n",
    "#plt.xlim(0,10000)\n",
    "plt.xscale(r\"log\")\n",
    "#plt.xlim([0.1, 10])\n",
    "#plt.xlim([0.01])\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(r\"MSE\")\n",
    "plt.title(r\"Ridge regression\")\n",
    "rbest_alpha = cv_results[\"alpha\"][cv_results[\"score\"].idxmin()]\n",
    "plt.annotate(\n",
    "    r\"Best $\\alpha$ = %.3f\" % rbest_alpha,\n",
    "    (rbest_alpha, cv_results[\"score\"].min()),\n",
    "    fontsize=16,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "#Functionalizes neural network\n",
    "#Will iterate through up to 3 layers\n",
    "#Output layer must be 8 neurons\n",
    "#to fit the size of defect_param\n",
    "\n",
    "def get_reg(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\", activity_regularizer=l2(rbest_alpha)))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(8))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull params from GridSearch and plug into variables\n",
    "#below to create model\n",
    "\n",
    "reg = KerasRegressor(\n",
    "    model=get_reg,\n",
    "    loss=\"mse\",\n",
    "    optimizer='adam',\n",
    "    optimizer__lr=0.001,\n",
    "    model__hidden_layer_sizes=(100,),\n",
    "    model__dropout=0.05,\n",
    "    metrics=[KerasRegressor.r_squared],\n",
    "    verbose=False,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loops to generate list of tuples for neuron list\n",
    "#Imperfect, gives repeats but not rearranged repeats\n",
    "#eg will give (32, 64, 512) but not (64, 32, 512) \n",
    "\n",
    "\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "neurons_list=[]\n",
    "neurons=list(range(32,544,32))\n",
    "for layers in range(1, 4):\n",
    "    neurons_per_layer=combinations_with_replacement(neurons,layers)\n",
    "    temp=[i for i in neurons_per_layer]\n",
    "    neurons_list.append(temp)\n",
    "neurons_list=list(neurons_list)\n",
    "print(neurons_list)\n",
    "\n",
    "#stay below 1.0\n",
    "lr_list = []\n",
    "for exponent in range(-4, 0):\n",
    "    lr_list.append(10**exponent)\n",
    "print(lr_list)\n",
    "\n",
    "#entries must be below 1\n",
    "dropout_list = list(np.linspace(0,0.5,5, endpoint=False))\n",
    "print(dropout_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 layer GridSearch gave (512,)\n",
    "#For loop to make list of tuples\n",
    "#(512, i)\n",
    "\n",
    "_2dim_layers=[]\n",
    "first_layer = 512\n",
    "for i in neurons:\n",
    "    temp_arch = (first_layer, i)\n",
    "    _2dim_layers.append(temp_arch)\n",
    "print(_2dim_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "best_params_log=[]\n",
    "params = {\n",
    "    'optimizer__lr':lr_list,\n",
    "    'model__hidden_layer_sizes':neurons_list,\n",
    "                                # (100,100), (200,200), (300,300), (400,400),\\\n",
    "                                # (500,500), (600,600), (700,700), (800,800),\n",
    "                                # (900,900), (1000,1000)],\n",
    "    'model__dropout':dropout_list,\n",
    "}\n",
    "gs = GridSearchCV(reg, params, refit=False, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "gs.fit(X_train_transform, y_train)\n",
    "print(gs.best_score_, gs.best_params_)\n",
    "\n",
    "best_params_log.append([gs.best_score_, gs.best_params_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the param_grid is created, can call function again\n",
    "#or \n",
    "\n",
    "reg = KerasRegressor(\n",
    "    model=get_reg,\n",
    "    loss=\"mse\",\n",
    "    optimizer='adam',\n",
    "    optimizer__lr=0.0001,\n",
    "    model__hidden_layer_sizes=(512,32),\n",
    "    model__dropout=0,\n",
    "    metrics=[KerasRegressor.r_squared],\n",
    "    verbose=False,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train_transform, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test_transform)\n",
    "y_pred = pd.DataFrame(10 ** y_pred, columns = targets.columns)\n",
    "display(y_pred)\n",
    "y_pred.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
